{"cells":[{"cell_type":"markdown","metadata":{"id":"oVWZ00jc9SNU"},"source":["## Coding Exercise #0703"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6HHiFblF9SNV"},"outputs":[],"source":["#Uncomment to force use of CPU.\n","#import os\n","#os.environ['CUDA_VISIBLE_DEVICES'] = ''\n","\n","#Suppress TF warnings\n","import os\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""]},{"cell_type":"markdown","metadata":{"id":"a1Y2jmih9SNV"},"source":["### 1. Softmax regression (multi-class logistic regression):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GtLI6cr9SNV"},"outputs":[],"source":["# import tensorflow as tf\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import scale\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_iris"]},{"cell_type":"markdown","metadata":{"id":"x48BWPfv9SNV"},"source":["#### 1.1. Read in the data:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VG2eiOAT9SNV","outputId":"416a93e1-f61f-4c4b-c8d8-1d3205fe830b"},"outputs":[{"data":{"text/plain":["dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# We will use Iris data.\n","# 4 explanatory variables.\n","# 3 classes for the response variable.\n","data_raw = load_iris()\n","data_raw.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2mrVwLjm9SNW"},"outputs":[],"source":["X = data_raw['data']\n","y = data_raw['target']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rFgINj_79SNW","outputId":"79556c0f-cbd4-4ee8-94f7-c430863f7301"},"outputs":[{"name":"stdout","output_type":"stream","text":["(150, 4)\n","(150,)\n"]}],"source":["# Check the shape.\n","print(X.shape)\n","print(y.shape)"]},{"cell_type":"markdown","metadata":{"id":"12JdU7HE9SNW"},"source":["#### 1.2. Data pre-processing:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TQrzgkRv9SNW","outputId":"fb054395-3487-46e6-c4e8-09062fd4ddbc"},"outputs":[{"data":{"text/plain":["(150, 3)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# One-Hot-Encoding.\n","y = np.array(pd.get_dummies(y, drop_first=False))               # drop_frist = False for one-hot-encoding.\n","y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eKTqzvqw9SNW"},"outputs":[],"source":["# Scaling\n","X = scale(X).astype('float32')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYsrIB_o9SNX"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)\n","n_train_size = y_train.shape[0]"]},{"cell_type":"markdown","metadata":{"id":"d5YDLDDQ9SNX"},"source":["#### 1.3. Do the necessary definitions:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LbW2Kfdd9SNX"},"outputs":[],"source":["batch_size = 100                                # Size of each (mini) batch.\n","n_epochs  = 30000                               # Number of epochs.\n","learn_rate = 0.05"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NlY4YpOx9SNX","outputId":"5d4b27be-7cf0-4e5a-b718-6486659f2d9a"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-17 09:12:52.250462: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"]}],"source":["W = tf.Variable(tf.ones([4,3],dtype=tf.float32))                 # Initial value of the weights = 1.\n","b = tf.Variable(tf.ones([3],dtype=tf.float32))                   # Initial value of the bias = 1."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uiMlC9cc9SNX"},"outputs":[],"source":["# Model.\n","def model(x):\n","    # Not strictly necessary to apply the softmax activation. => in the end we will apply argmax() function to predict the label!\n","    # return tf.nn.softmax(tf.matmul(X, W) + b)\n","    return tf.matmul(x, W) + b"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5bvWW_Zj9SNX"},"outputs":[],"source":["# Loss = cross entropy.\n","def loss_fn(y_true, y_pred):\n","    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_true, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_ptzVpo9SNX"},"outputs":[],"source":["optimizer = tf.optimizers.SGD(learning_rate=learn_rate)"]},{"cell_type":"markdown","metadata":{"id":"7M9ONbSy9SNX"},"source":["#### 1.4. Training and Testing:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9UD5_Cjr9SNX","outputId":"563e7414-bc36-4f3a-cd4c-9d1b9e3b8578"},"outputs":[{"name":"stdout","output_type":"stream","text":["Step : 2000\n","Step : 4000\n","Step : 6000\n","Step : 8000\n","Step : 10000\n","Step : 12000\n","Step : 14000\n","Step : 16000\n","Step : 18000\n","Step : 20000\n","Step : 22000\n","Step : 24000\n","Step : 26000\n","Step : 28000\n","Step : 30000\n"]}],"source":["@tf.function\n","def train_step(X, y):\n","    with tf.GradientTape() as tape:\n","        y_pred = model(X)\n","        loss = loss_fn(y, y_pred)\n","    gradients = tape.gradient(loss, [W, b])\n","    optimizer.apply_gradients(zip(gradients, [W, b]))\n","\n","# Training.\n","for i in range(n_epochs):\n","    idx_rnd = np.random.choice(range(n_train_size), batch_size, replace=False)  # Random sampling w/o replacement for the batch indices.\n","    batch_X, batch_y = [X_train[idx_rnd, :], y_train[idx_rnd, :]]               # Get a batch.\n","    train_step(batch_X, batch_y)\n","    if (i + 1) % 2000 == 0:\n","        print(\"Step : {}\".format(i + 1))                                        # Print the step number at every multiple of 2000.\n","\n","# Testing.\n","correct_predictions = tf.equal(tf.argmax(y_test, axis=1), tf.argmax(model(X_test), axis=1))  # In argmax(), axis=1 means horizontal direction.\n","accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))                            # Recast the Boolean as float32 first. Then calculate the mean.\n","accuracy_value = accuracy.numpy()                                                              # Actually run the test with the test data."]},{"cell_type":"markdown","metadata":{"id":"iSN9y2g99SNY"},"source":["Print the testing result."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9PHvUbe9SNY","outputId":"cab20330-8a53-4efa-9302-6112238f0c8e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy = 0.933\n"]}],"source":["print(\"Accuracy = {:5.3f}\".format(accuracy_value))"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}