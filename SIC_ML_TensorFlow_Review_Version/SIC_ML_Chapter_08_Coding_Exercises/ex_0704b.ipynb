{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Exercise #0704b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to force use of CPU.\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "#Suppress TF warnings\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Multi-layer neural network to recognize the handswritten digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Download the MNIST data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verbosity_saved = tf.logging.get_verbosity()                                           # Save the current verbosity lebel if needed.\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)                                  # Set the verbosity lebel high so that most warnings are ignored. \n",
    "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = tf.keras.datasets.mnist.load_data()   # Download the data.\n",
    "type(mnist_train_images)                                                                            # Check the type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Take a look at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_images = mnist_train_images.astype('float32') / 255\n",
    "mnist_test_images = mnist_test_images.astype('float32') / 255\n",
    "\n",
    "mnist_train_images = np.expand_dims(mnist_train_images, -1).reshape((mnist_train_images.shape[0],-1))\n",
    "mnist_test_images = np.expand_dims(mnist_test_images, -1).reshape((mnist_test_images.shape[0],-1))\n",
    "\n",
    "mnist_train_labels = tf.keras.utils.to_categorical(mnist_train_labels, 10)          # one-hot encoding labels\n",
    "mnist_test_labels = tf.keras.utils.to_categorical(mnist_test_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i_image= 1                                                      # Image index. You can change it at will.\n",
    "a_single_image = mnist_train_images[i_image].reshape(28,28)     #  Reshape as a 2D array.\n",
    "plt.imshow(1-a_single_image, cmap='gist_gray')                  #  Display as grayscale image.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN : 0.0\n",
      "MAX : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Check for the minimum and maximum pixel value.\n",
    "# The data has been min-max-scaled already!\n",
    "print(\"MIN : {}\".format(a_single_image.min()))\n",
    "print(\"MAX : {}\".format(a_single_image.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Do the necessary definitions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30                                # Size of each (mini) batch.\n",
    "n_epochs  = 20000                              # Number of epochs.\n",
    "learn_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 10:30:33.583663: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# We are building a multi-layer neural network. Thus, several sets of (b,W) required.\n",
    "# Parameters that connect the input layer with the first hidden layer. \n",
    "W1 = tf.Variable(tf.random.normal([784,30],0,1))   # Input = 784 nodes, Output = 30 nodes.   \n",
    "b1 = tf.Variable(tf.random.normal([30],0,1))     \n",
    "# Parameters that connect the first hidden layer with the second hidden layer.\n",
    "W2 = tf.Variable(tf.random.normal([30,15],0,1))    # Input = 30 nodes, Output = 15 nodes (the same as the number of output nodes at the previous layer).\n",
    "b2 = tf.Variable(tf.random.normal([15],0,1)) \n",
    "# Parameters that connect the second hidden layer with the output layer.\n",
    "W3 = tf.Variable(tf.random.normal([15,10],0,1))    # Input = 15 nodes, Output = 10 nodes (the same as the number of output nodes at the previous layer).\n",
    "b3 = tf.Variable(tf.random.normal([10],0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A multi-layer model.\n",
    "# As before, the Softmax activation at the output layer is optional. \n",
    "#hidden1 = tf.nn.sigmoid(tf.matmul(X_ph,W1) + b1)\n",
    "#hidden2 = tf.nn.sigmoid(tf.matmul(hidden1,W2) + b2)\n",
    "#y_model =  tf.matmul(hidden2, W3) + b3\n",
    "\n",
    "def model(X):\n",
    "    hidden1 = tf.nn.sigmoid(tf.matmul(X, W1) + b1)\n",
    "    hidden2 = tf.nn.sigmoid(tf.matmul(hidden1, W2) + b2)\n",
    "    y_model =  tf.matmul(hidden2, W3) + b3\n",
    "    return y_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss  = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_ph, logits=y_model))   # loss = Cross Entropy. \n",
    "def loss_fn(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = tf.train.AdamOptimizer(learning_rate = learn_rate)     # A better optimizer.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate)      # A better optimizer.\n",
    "\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate = learn_rate)       # A basic optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Training and Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# train_dataset = train_dataset.batch(batch_size).repeat()                                    # if clear epoch separation is needed\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Training.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m---> 16\u001b[0m     batch_X, batch_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m                                \u001b[38;5;66;03m# Get a batch.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     train_step(batch_X, batch_y)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:809\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    808\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:772\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 772\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    777\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3081\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3080\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3081\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3082\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIteratorGetNext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3083\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3084\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3085\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train_step(X, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)\n",
    "        loss_value = loss_fn(y, y_pred)\n",
    "        gradients = tape.gradient(loss_value, [W1, b1, W2, b2, W3, b3])\n",
    "        optimizer.apply_gradients(zip(gradients, [W1, b1, W2, b2, W3, b3]))\n",
    "\n",
    "# To replicate functionalities of tensorflow v1.* next_batch():\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((mnist_train_images, mnist_train_labels))  # join together images and labels\n",
    "train_dataset = train_dataset.repeat().batch(batch_size)                                      # yield batches that straddle epoch boundaries\n",
    "# train_dataset = train_dataset.batch(batch_size).repeat()                                    # if clear epoch separation is needed\n",
    "\n",
    "# Training.\n",
    "for i in range(n_epochs):\n",
    "    batch_X, batch_y = next(iter(train_dataset))                                # Get a batch.\n",
    "    train_step(batch_X, batch_y)\n",
    "    if (i + 1) % 2000 == 0:\n",
    "        print(\"Step : {}\".format(i + 1))                                        # Print the step number at every multiple of 2000.\n",
    "\n",
    "# Testing.\n",
    "correct_predictions = tf.equal(tf.argmax(mnist_test_labels, axis=1), tf.argmax(model(mnist_test_images), axis=1))  # In argmax(), axis=1 means horizontal direction.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))                            # Recast the Boolean as float32 first. Then calculate the mean.\n",
    "accuracy_value = accuracy.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the testing result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.958\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = {:5.3f}\".format(accuracy_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the equivalent version using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 09:38:20.868201: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-15 09:38:21.472462: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the verbosity level of TensorFlow to ignore most warnings\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 09:38:34.377961: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.398625: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.398667: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.400705: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.400744: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.400772: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.549467: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.549523: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.549531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-15 09:38:34.549565: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.549584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4699 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Normalize pixel values to the range [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape data to match the shape expected by the neural network\n",
    "x_train = x_train.reshape((-1, 784))\n",
    "x_test = x_test.reshape((-1, 784))\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.one_hot(y_train, depth=10)\n",
    "y_test = tf.one_hot(y_test, depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size and number of epochs\n",
    "batch_size = 30\n",
    "n_epochs = 20\n",
    "learn_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(30, activation='sigmoid', input_shape=(784,)),\n",
    "    keras.layers.Dense(15, activation='sigmoid'),\n",
    "    keras.layers.Dense(10)  # No activation for the output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size=len(x_train)).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715758753.853088    3007 service.cc:145] XLA service 0x7fa644005cb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1715758753.853135    3007 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce GTX 1060 6GB, Compute Capability 6.1\n",
      "2024-05-15 09:39:13.870501: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-15 09:39:13.940613: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  96/2000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4205 - loss: 1.8778"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1715758755.191442    3007 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8273 - loss: 0.6281\n",
      "Epoch 2/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.1956\n",
      "Epoch 3/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1729\n",
      "Epoch 4/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9545 - loss: 0.1498\n",
      "Epoch 5/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9571 - loss: 0.1439\n",
      "Epoch 6/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9565 - loss: 0.1419\n",
      "Epoch 7/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9615 - loss: 0.1234\n",
      "Epoch 8/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9616 - loss: 0.1268\n",
      "Epoch 9/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9656 - loss: 0.1156\n",
      "Epoch 10/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9668 - loss: 0.1084\n",
      "Epoch 11/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.1083\n",
      "Epoch 12/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9670 - loss: 0.1078\n",
      "Epoch 13/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.1039\n",
      "Epoch 14/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.1019\n",
      "Epoch 15/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.1029\n",
      "Epoch 16/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.0937\n",
      "Epoch 17/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.0954\n",
      "Epoch 18/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.0895\n",
      "Epoch 19/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0955\n",
      "Epoch 20/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9734 - loss: 0.0860\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.1652\n",
      "Test Accuracy: 0.9567999839782715\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_dataset, epochs=n_epochs, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
