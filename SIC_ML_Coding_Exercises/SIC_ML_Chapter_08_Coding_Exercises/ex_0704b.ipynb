{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Exercise #0704b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Multi-layer neural network to recognize the handswritten digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data            # MNIST handwritten digits data!\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Download the MNIST data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbosity_saved = tf.logging.get_verbosity()                        # Save the current verbosity lebel if needed.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)                            # Set the verbosity lebel high so that most warnings are ignored. \n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)         # Download the data.\n",
    "type(mnist)                                                           # Check the type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Take a look at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data X shape: {}\".format((mnist.train.images).shape))\n",
    "print(\"Training data y shape: {}\".format((mnist.train.labels).shape))\n",
    "print(\"Training data cases: {}\".format(mnist.train.num_examples))\n",
    "print(\"\\n\")\n",
    "print(\"Testing data X shape: {}\".format((mnist.test.images).shape))\n",
    "print(\"Testing data y shape: {}\".format((mnist.test.labels).shape))\n",
    "print(\"Testing data cases: {}\".format(mnist.test.num_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_image= 1                                                    # Image index. You can change it at will.\n",
    "a_single_image = mnist.train.images[i_image].reshape(28,28)     #  Reshape as a 2D array.\n",
    "plt.imshow(1-a_single_image, cmap='gist_gray')                  #  Display as grayscale image.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the minimum and maximum pixel value.\n",
    "# The data has been min-max-scaled already!\n",
    "print(\"MIN : {}\".format(a_single_image.min()))                 \n",
    "print(\"MAX : {}\".format(a_single_image.max())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Do the necessary definitions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30                                # Size of each (mini) batch.\n",
    "n_epochs  = 20000                              # Number of epochs.\n",
    "learn_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are building a multi-layer neural network. Thus, several sets of (b,W) required.\n",
    "# Parameters that connect the input layer with the first hidden layer. \n",
    "W1 = tf.Variable(tf.random_normal([784,30],0,1))   # Input = 784 nodes, Output = 30 nodes.   \n",
    "b1 = tf.Variable(tf.random_normal([30],0,1))     \n",
    "# Parameters that connect the first hidden layer with the second hidden layer.\n",
    "W2 = tf.Variable(tf.random_normal([30,15],0,1))    # Input = 30 nodes, Output = 15 nodes (the same as the number of output nodes at the previous layer).\n",
    "b2 = tf.Variable(tf.random_normal([15],0,1)) \n",
    "# Parameters that connect the second hidden layer with the output layer.\n",
    "W3 = tf.Variable(tf.random_normal([15,10],0,1))    # Input = 15 nodes, Output = 10 nodes (the same as the number of output nodes at the previous layer).\n",
    "b3 = tf.Variable(tf.random_normal([10],0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ph = tf.placeholder(tf.float32, [None, 784])   # Indetermined number of cases (observations). Input nodes = 784.\n",
    "y_ph = tf.placeholder(tf.float32,[None,10])      # The response variable has been one-hot-encoded. There are 10 output nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A multi-layer model.\n",
    "# As before, the Softmax activation at the output layer is optional. \n",
    "hidden1 = tf.nn.sigmoid(tf.matmul(X_ph,W1) + b1)\n",
    "hidden2 = tf.nn.sigmoid(tf.matmul(hidden1,W2) + b2)\n",
    "y_model =  tf.matmul(hidden2, W3) + b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss  = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_ph, logits=y_model))   # loss = Cross Entropy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = learn_rate)     # A better optimizer.\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate = learn_rate)       # A basic optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Training and Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "        # Variables initialization.\n",
    "        sess.run(init)\n",
    "        # Training.\n",
    "        for i in range(n_epochs):\n",
    "            batch_X, batch_y = mnist.train.next_batch(batch_size)                      # Sample a batch!\n",
    "            my_feed = {X_ph:batch_X, y_ph:batch_y}\n",
    "            sess.run(train, feed_dict = my_feed)\n",
    "            if (i + 1) % 2000 == 0: print(\"Step = {}\".format(i + 1))                   # Print the step number at every multiple of 2000.\n",
    "         # Testing.\n",
    "        correct_predictions = tf.equal(tf.argmax(y_ph, axis=1), tf.argmax(y_model, axis=1))          # In argmax(), axis=1 means horizontal direction.\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))                          # Recast the Boolean as float32 first. Then calculate the mean.\n",
    "        accuracy_value = sess.run(accuracy, feed_dict={X_ph:mnist.test.images, y_ph:mnist.test.labels})   # Use all of the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the testing result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy = {:5.3f}\".format(accuracy_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
