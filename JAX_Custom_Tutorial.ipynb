{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15f8d8cc-e751-4f4a-8130-91b321a48c83",
   "metadata": {},
   "source": [
    "# JAX Key Aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810d8c38-d19d-49f6-877b-cc648879eb0c",
   "metadata": {},
   "source": [
    "Some of the example are taken from \n",
    "https://jax.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "086df29a-2903-4234-928c-61a5f8dc779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppress warnings\n",
    "import os\n",
    "import absl.logging\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "absl.logging.set_verbosity('error')\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "absl.logging.set_stderrthreshold(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74169952-8466-4ade-8648-1cabbd23d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0a0571-95a6-4a39-b900-a07e66d113af",
   "metadata": {},
   "source": [
    "## Automatic detection of the hardware back-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3c74ce-1e62-4208-a650-ba401901f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af7f01-b771-41f7-ae6d-32e8a954078e",
   "metadata": {},
   "source": [
    "If you have correctly installed a GPU, it will automatically detect and use for your computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55eb8409-adf4-45c1-8711-8a6e497f15a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{cuda(id=0)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = jnp.arange(5)\n",
    "\n",
    "#If you want to know if your array is assigned to what devices.\n",
    "x.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24de77f-2fc6-43d2-8583-f3450515e404",
   "metadata": {},
   "source": [
    "If you want to force for your pourposes the CPU utilization as default don't forget to specify this.\n",
    "\n",
    "Pay attention you have to restart the notebook if you have already execute the previous cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d983b2a-a2fb-4c9c-b878-03d5afc0790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['JAX_PLATFORM_NAME'] = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d25376-3072-4371-8b14-74484dcf899d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{CpuDevice(id=0)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "y = jnp.arange(5)\n",
    "\n",
    "#If you want to know if your array is assigned to what devices.\n",
    "y.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de310a54-6612-4e97-b1af-a6cfe4106a7a",
   "metadata": {},
   "source": [
    "Alternatively you are forced to specify it manually. Like in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ce16a8-06d1-4559-8873-1607c537c906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array z: [0 1 2 3 4]\n",
      "Array z is on device: {CpuDevice(id=0)}\n",
      "Array w: [0 1 2 3 4]\n",
      "Array w is on device: {cuda(id=0)}\n"
     ]
    }
   ],
   "source": [
    "from jax import devices\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "z = jax.device_put(jnp.arange(5),device=devices('cpu')[0])\n",
    "w = jax.device_put(jnp.arange(5),device=devices('gpu')[0])\n",
    "\n",
    "print(\"Array z:\", z)\n",
    "print(\"Array z is on device:\", z.devices())\n",
    "\n",
    "print(\"Array w:\", w)\n",
    "print(\"Array w is on device:\", w.devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57346fae-4ca8-41f1-a73a-21af11d25437",
   "metadata": {},
   "source": [
    "## Similarity with NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bbf0c2-fde2-4439-8f0f-b1591fa9bcaf",
   "metadata": {},
   "source": [
    "Remember that NumPy only supports CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f4ab9b-b2c0-4200-bb33-99888e4f1f4c",
   "metadata": {},
   "source": [
    "### Basic NumPy Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb3e52d-0c2f-490a-8068-7d8e43c85bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr: [1 2 3]\n",
      "\n",
      "zeros: \n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "ones: \n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "arange: [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "linspace: [0.   0.25 0.5  0.75 1.  ]\n",
      "\n",
      "eye: \n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      "random: \n",
      "[[0.5488135  0.71518937 0.60276338]\n",
      " [0.54488318 0.4236548  0.64589411]]\n",
      "\n",
      "A: [1 2 3]\n",
      "\n",
      "B: [4 5 6]\n",
      "\n",
      "A+B: [5 7 9]\n",
      "\n",
      "A-B: [-3 -3 -3]\n",
      "\n",
      "A*B: [ 4 10 18]\n",
      "\n",
      "A/B: [0.25 0.4  0.5 ]\n",
      "\n",
      "dot: 32\n",
      "\n",
      "arr2: [1 2 3 4 5]\n",
      "\n",
      "SUM (arr): 15\n",
      "\n",
      "MEAN (arr): 3.0\n",
      "\n",
      "MAX (arr): 5\n",
      "\n",
      "MIN (arr): 1\n",
      "\n",
      "arr2[1:4]: [2 3 4]\n",
      "\n",
      "arr3:[1 2 3 4 5 6]\n",
      "\n",
      "reshaped:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "a1: \n",
      "[[1 2]\n",
      " [3 4]]\n",
      "\n",
      "b1: \n",
      "[[5 6]\n",
      " [7 8]]\n",
      "\n",
      "MatMul (a1,b1): \n",
      "[[19 22]\n",
      " [43 50]]\n",
      "\n",
      "Det (a1): -2.0000000000000004\n",
      "\n",
      "Inv (a1): \n",
      "[[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n",
      "\n",
      "Eigenvalues (a1): [-0.37228132  5.37228132] \n",
      "Eigenvectors(a1): \n",
      "[[-0.82456484 -0.41597356]\n",
      " [ 0.56576746 -0.90937671]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Basic Array Operations \n",
    "\n",
    "arr = np.array([1, 2, 3])\n",
    "zeros = np.zeros((2, 3))\n",
    "ones = np.ones((2, 3))\n",
    "arange = np.arange(10)\n",
    "linspace = np.linspace(0, 1, 5)\n",
    "eye = np.eye(3)\n",
    "\n",
    "np.random.seed(0)\n",
    "random = np.random.rand(2, 3)\n",
    "\n",
    "#Aritmetical operations\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "\n",
    "add = a + b\n",
    "subtract = a - b\n",
    "multiply = a * b\n",
    "divide = a / b\n",
    "dot = np.dot(a, b)\n",
    "\n",
    "\n",
    "#Aggregate operations\n",
    "arr2 = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "sum_arr = np.sum(arr2)\n",
    "mean_arr = np.mean(arr2)\n",
    "max_arr = np.max(arr2)\n",
    "min_arr = np.min(arr2)\n",
    "\n",
    "#Indexing slicing\n",
    "sliced = arr2[1:4]\n",
    "indexed = arr2[2]\n",
    "indexed2= arr2[-1]\n",
    "\n",
    "#Reshaping\n",
    "arr3 = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "reshaped = arr3.reshape((2, 3))\n",
    "\n",
    "#Linear Algebra\n",
    "a1 = np.array([[1, 2], [3, 4]])\n",
    "b1 = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "matmul = np.matmul(a1, b1)\n",
    "det = np.linalg.det(a1)\n",
    "inv = np.linalg.inv(a1)\n",
    "eigvals, eigvecs = np.linalg.eig(a1)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"arr: {arr}\")\n",
    "print(f\"\\nzeros: \\n{zeros}\")\n",
    "print(f\"\\nones: \\n{ones}\")\n",
    "print(f\"\\narange: {arange}\")\n",
    "print(f\"\\nlinspace: {linspace}\")\n",
    "print(f\"\\neye: \\n{eye}\")\n",
    "print(f\"\\nrandom: \\n{random}\")\n",
    "\n",
    "print(f\"\\nA: {a}\")\n",
    "print(f\"\\nB: {b}\")\n",
    "\n",
    "print(f\"\\nA+B: {add}\")\n",
    "print(f\"\\nA-B: {subtract}\")\n",
    "print(f\"\\nA*B: {multiply}\")\n",
    "print(f\"\\nA/B: {divide}\")\n",
    "print(f\"\\ndot: {dot}\")\n",
    "\n",
    "print(f\"\\narr2: {arr2}\")\n",
    "print(f\"\\nSUM (arr): {sum_arr}\")\n",
    "print(f\"\\nMEAN (arr): {mean_arr}\")\n",
    "print(f\"\\nMAX (arr): {max_arr}\")\n",
    "print(f\"\\nMIN (arr): {min_arr}\")\n",
    "\n",
    "\n",
    "print (f\"\\narr2[1:4]: {sliced}\")\n",
    "\n",
    "print(f\"\\narr3:{arr3}\")\n",
    "print(f\"\\nreshaped:\\n{reshaped}\")\n",
    "\n",
    "print(f\"\\na1: \\n{a1}\")\n",
    "print(f\"\\nb1: \\n{b1}\")\n",
    "print(f\"\\nMatMul (a1,b1): \\n{matmul}\")\n",
    "print(f\"\\nDet (a1): {det}\")\n",
    "print(f\"\\nInv (a1): \\n{inv}\")\n",
    "print(f\"\\nEigenvalues (a1): {eigvals} \\nEigenvectors(a1): \\n{eigvecs}\\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f0541-0ae3-4359-9883-515ac6403cdd",
   "metadata": {},
   "source": [
    "### Basic equivalent Jax Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8f9a8c2-7c94-4a94-9c86-0f9a9a972d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr: [1 2 3]\n",
      "\n",
      "zeros: \n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "ones: \n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "arange: [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "linspace: [0.   0.25 0.5  0.75 1.  ]\n",
      "\n",
      "eye: \n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      "random: \n",
      "[[0.57450044 0.09968603 0.7419659 ]\n",
      " [0.8941783  0.59656656 0.45325184]]\n",
      "\n",
      "A: [1 2 3]\n",
      "\n",
      "B: [4 5 6]\n",
      "\n",
      "A+B: [5 7 9]\n",
      "\n",
      "A-B: [-3 -3 -3]\n",
      "\n",
      "A*B: [ 4 10 18]\n",
      "\n",
      "A/B: [0.25 0.4  0.5 ]\n",
      "\n",
      "dot: 32\n",
      "\n",
      "arr: [1 2 3 4 5]\n",
      "\n",
      "SUM (arr): 15\n",
      "\n",
      "MEAN (arr): 3.0\n",
      "\n",
      "MAX (arr): 5\n",
      "\n",
      "MIN (arr): 1\n",
      "\n",
      "arr3:[1 2 3 4 5 6]\n",
      "\n",
      "reshaped:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "from jax import random\n",
    "\n",
    "#Basic Array Operations \n",
    "\n",
    "arr = jnp.array([1, 2, 3])\n",
    "zeros = jnp.zeros((2, 3))\n",
    "ones = jnp.ones((2, 3))\n",
    "arange = jnp.arange(10)\n",
    "linspace = jnp.linspace(0, 1, 5)\n",
    "eye = jnp.eye(3)\n",
    "rng = random.PRNGKey(0)\n",
    "random_arr = random.uniform(rng, (2, 3))\n",
    "\n",
    "#Aritmetical operations\n",
    "a = jnp.array([1, 2, 3])\n",
    "b = jnp.array([4, 5, 6])\n",
    "\n",
    "add = a + b\n",
    "subtract = a - b\n",
    "multiply = a * b\n",
    "divide = a / b\n",
    "dot = jnp.dot(a, b)\n",
    "\n",
    "#Aggregate operations\n",
    "arr2 = jnp.array([1, 2, 3, 4, 5])\n",
    "\n",
    "sum_arr = jnp.sum(arr2)\n",
    "mean_arr = jnp.mean(arr2)\n",
    "max_arr = jnp.max(arr2)\n",
    "min_arr = jnp.min(arr2)\n",
    "\n",
    "#Indexing slicing\n",
    "sliced = arr2[1:4]\n",
    "indexed = arr2[2]\n",
    "indexed2= arr2[-1]\n",
    "\n",
    "\n",
    "#Reshaping\n",
    "arr3 = jnp.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "reshaped = arr3.reshape((2, 3))\n",
    "\n",
    "#Linear Algebra\n",
    "a1 = jnp.array([[1, 2], [3, 4]])\n",
    "b1 = jnp.array([[5, 6], [7, 8]])\n",
    "\n",
    "matmul = jnp.matmul(a1, b1)\n",
    "det = jnp.linalg.det(a1)\n",
    "inv = jnp.linalg.inv(a1)\n",
    "eigvals, eigvecs = jnp.linalg.eig(a1)\n",
    "\n",
    "\n",
    "print(f\"arr: {arr}\")\n",
    "print(f\"\\nzeros: \\n{zeros}\")\n",
    "print(f\"\\nones: \\n{ones}\")\n",
    "print(f\"\\narange: {arange}\")\n",
    "print(f\"\\nlinspace: {linspace}\")\n",
    "print(f\"\\neye: \\n{eye}\")\n",
    "print(f\"\\nrandom: \\n{random_arr}\")\n",
    "\n",
    "print(f\"\\nA: {a}\")\n",
    "print(f\"\\nB: {b}\")\n",
    "\n",
    "print(f\"\\nA+B: {add}\")\n",
    "print(f\"\\nA-B: {subtract}\")\n",
    "print(f\"\\nA*B: {multiply}\")\n",
    "print(f\"\\nA/B: {divide}\")\n",
    "print(f\"\\ndot: {dot}\")\n",
    "\n",
    "print(f\"\\narr: {arr2}\")\n",
    "print(f\"\\nSUM (arr): {sum_arr}\")\n",
    "print(f\"\\nMEAN (arr): {mean_arr}\")\n",
    "print(f\"\\nMAX (arr): {max_arr}\")\n",
    "print(f\"\\nMIN (arr): {min_arr}\")\n",
    "\n",
    "print(f\"\\narr3:{arr3}\")\n",
    "print(f\"\\nreshaped:\\n{reshaped}\")\n",
    "\n",
    "print(f\"\\na1: \\n{a1}\")\n",
    "print(f\"\\nb1: \\n{b1}\")\n",
    "print(f\"\\nMatMul (a1,b1): \\n{matmul}\")\n",
    "print(f\"\\nDet (a1): {det}\")\n",
    "print(f\"\\nInv (a1): \\n{inv}\")\n",
    "print(f\"\\nEigenvalues (a1): {eigvals} \\nEigenvectors(a1): \\n{eigvecs}\\n \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52071d93-8ac4-48ff-b949-5afe58fcb67f",
   "metadata": {},
   "source": [
    "### Example nr. 1 - Matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac019119-16b5-4241-bf3c-c3012cab323e",
   "metadata": {},
   "source": [
    "#### NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e65889-b60e-47f4-a7f0-51b0629c7376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2496.2744 2466.5544 2470.9575 ... 2494.8926 2525.964  2467.1694]\n",
      " [2461.0415 2469.6577 2484.0947 ... 2477.7363 2494.6555 2485.727 ]\n",
      " [2487.7373 2482.263  2493.5962 ... 2511.0745 2535.1755 2494.8848]\n",
      " ...\n",
      " [2518.0334 2511.9395 2514.2825 ... 2530.6328 2551.318  2508.673 ]\n",
      " [2512.0613 2488.3813 2483.8801 ... 2516.4438 2516.2053 2489.3577]\n",
      " [2460.9507 2452.2944 2478.3572 ... 2476.3423 2494.7036 2460.0671]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Generate two random matrices\n",
    "size = 10000\n",
    "A = np.random.rand(size, size).astype(np.float32)\n",
    "B = np.random.rand(size, size).astype(np.float32)\n",
    "print (np.dot(A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f044cde3-4e63-4252-82b0-a660375c67dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.53 s ± 168 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.dot(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729a9869-17e6-4d18-8394-6504c04f268b",
   "metadata": {},
   "source": [
    "#### JAX using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b5ae96-f2c0-49e1-a69e-547891f7a4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2496.2742 2466.5542 2470.9575 ... 2494.8923 2525.9636 2467.1692]\n",
      " [2461.0415 2469.6575 2484.095  ... 2477.737  2494.6555 2485.727 ]\n",
      " [2487.7368 2482.2634 2493.5952 ... 2511.0747 2535.175  2494.885 ]\n",
      " ...\n",
      " [2518.033  2511.9395 2514.2822 ... 2530.6328 2551.3179 2508.6733]\n",
      " [2512.06   2488.3813 2483.8801 ... 2516.4438 2516.206  2489.358 ]\n",
      " [2460.9504 2452.2944 2478.3574 ... 2476.3418 2494.7039 2460.0674]]\n"
     ]
    }
   ],
   "source": [
    "#jax.config.update(\"jax_enable_x64\", True)  # Optional: if using float64\n",
    "\n",
    "JAX_A = jax.device_put(jnp.array(A),device=devices('cpu')[0]) \n",
    "JAX_B = jax.device_put(jnp.array(B),device=devices('cpu')[0]) \n",
    "\n",
    "print (jnp.dot(JAX_A, JAX_B).block_until_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a619a99-47a3-4e5a-a6fc-931c1e6eb7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.22 s ± 52.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jnp.dot(JAX_A, JAX_B).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e5b3b-d5c9-44de-ad65-8a33a7b1c726",
   "metadata": {},
   "source": [
    "#### JAX using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47c8422-c1e6-4003-935c-ca587f687be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "JAX_A = jax.device_put(jnp.array(A),device=devices('gpu')[0]) \n",
    "JAX_B = jax.device_put(jnp.array(B),device=devices('gpu')[0]) \n",
    "print (jnp.dot(JAX_A, JAX_B).block_until_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64bfedf6-1ab9-4065-bb09-10d8d805bc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484 ms ± 2.97 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jnp.dot(JAX_A, JAX_B).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adabd4fa-edd4-40f5-bc78-659847dd728a",
   "metadata": {},
   "source": [
    "As we can see matrix multiplication performs better on GPU and it is achiavable only with JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90219ddf-0722-454e-af35-3083e591785b",
   "metadata": {},
   "source": [
    "### Example nr. 2 - Computation on specific functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4958a0-6192-4f90-9b07-55296e4ee47c",
   "metadata": {},
   "source": [
    "#### NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357baa85-61da-44ff-bf75-a430f6307663",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones((10000, 10000))\n",
    "y = np.arange(10000)\n",
    "\n",
    "z = np.sin(x) + np.cos(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a653d3e-23ea-4e19-9497-3befa56a5ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "819 ms ± 36.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.sin(x) + np.cos(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba010d2-6426-4b5e-965b-2cb460afc39f",
   "metadata": {},
   "source": [
    "#### JAX using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b66ca5-94f9-4f21-9c39-c86d306396d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=jax.device_put(jnp.ones((10000, 10000)),device=devices('cpu')[0]) \n",
    "y=jax.device_put(jnp.arange(10000),device=devices('cpu')[0]) \n",
    "\n",
    "z = jnp.sin(x) + jnp.cos(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa62d277-2207-4286-bcc0-60a429293aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 ms ± 7.61 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jnp.sin(x) + jnp.cos(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb157529-3142-453b-bd88-9d3c8750e953",
   "metadata": {},
   "source": [
    "#### JAX using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e010e821-4790-4a5e-814a-c90090ded26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=jax.device_put(jnp.ones((10000, 10000)),device=devices('gpu')[0]) \n",
    "y=jax.device_put(jnp.arange(10000),device=devices('gpu')[0]) \n",
    "\n",
    "z = jnp.sin(x) + jnp.cos(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4618c2e-ef76-4a44-8898-e9922b3fc0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.7 ms ± 19.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jnp.sin(x) + jnp.cos(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9a4044-0689-469c-80b4-752b00ae1dbd",
   "metadata": {},
   "source": [
    "In this case also on CPU the operation executed with Jax performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd288b-954a-4b79-ba57-11a58c7ef53f",
   "metadata": {},
   "source": [
    "## Differences with NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3fb9a7-1d14-4a3d-a947-1e2237935ca0",
   "metadata": {},
   "source": [
    "In JAX, data structures are **immutable** by default, meaning they cannot be modified once created. Instead, when an operation that would typically modify an array is performed, JAX returns a new array with the modifications, leaving the original array unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66c3e68-4d99-492a-9905-661eb41307f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errore: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html\n"
     ]
    }
   ],
   "source": [
    "x = jnp.array([1, 2, 3, 4, 5])\n",
    "\n",
    "#Let's try to modify an element inside the array\n",
    "try:\n",
    "    x[0] = 10\n",
    "except Exception as e:\n",
    "    print(f\"Errore: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be52e012-cdc8-4b67-bdb5-c611ee5ff0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array (x): [1 2 3 4 5]\n",
      "Modified Array (y): [10  2  3  4  5]\n"
     ]
    }
   ],
   "source": [
    "#The correct way to do\n",
    "\n",
    "#Creating a new array with the desired modification\n",
    "y = x.at[0].set(10)\n",
    "\n",
    "print(\"Original Array (x):\", x)\n",
    "print(\"Modified Array (y):\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bce4dc-109f-44a0-9a6b-bf17366b3a95",
   "metadata": {},
   "source": [
    "## Just in time compilation (JIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc271c00-e6e3-4e8d-8dc7-c6062e76678c",
   "metadata": {},
   "source": [
    "Let's take as example the computation of the softmax function. Here is reported a variant that garantees numerical stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123d477d-839d-4990-bbeb-d272a71991a0",
   "metadata": {},
   "source": [
    "### JAX jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97df155-47bf-49ff-8ff8-e4a761886f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jit\n",
    "\n",
    "# Define the softmax function\n",
    "def softmax(logits):\n",
    "    exp_logits = jnp.exp(logits - jnp.max(logits, axis=-1, keepdims=True))\n",
    "    return exp_logits / jnp.sum(exp_logits, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c6d427-1164-4a8e-95fe-3dbf7e6c4124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random logits for testing\n",
    "key = jax.random.PRNGKey(0)\n",
    "logits = jax.random.normal(key, (1000, 10))  # 1000 samples, 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "273bf3e8-c7ac-4938-90e1-7c2f220e6c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563 µs ± 46.9 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Measure time without JIT\n",
    "%timeit softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fedf09e-e52f-4303-92c9-89b7031bf19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_softmax = jit(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c7bec40-c452-45e0-8f11-112c04d248b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 µs ± 4.82 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Measure time with JIT\n",
    "%timeit jit_softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b656275-19a7-4459-8a5d-2392e1f42006",
   "metadata": {},
   "source": [
    "### Tensorflow jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550d7b61-15d4-43ee-8f2a-2a4cf85f246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the softmax function\n",
    "@tf.function\n",
    "def softmax(logits):\n",
    "    # Subtract the max logit for numerical stability\n",
    "    exp_logits = tf.exp(logits - tf.reduce_max(logits, axis=-1, keepdims=True))\n",
    "    # Normalize to get probabilities\n",
    "    return exp_logits / tf.reduce_sum(exp_logits, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "930983b8-f1c2-487d-bdac-f176e00cc045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random logits for testing\n",
    "logits = tf.random.normal((100000, 10))  # 1000 samples, 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ab0f217-7eff-4e51-af58-2117280433dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697 µs ± 19.8 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49577ce2-959a-4904-b90d-165b974d181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure time with JIT\n",
    "@tf.function(jit_compile=True) \n",
    "def softmax_with_jit(logits):\n",
    "    return softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b15309-7a9f-48b5-8d14-ca3ae8cb4a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443 µs ± 63 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717694244.790568    2604 service.cc:145] XLA service 0x5593cf978a30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1717694244.790679    2604 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce GTX 1060 6GB, Compute Capability 6.1\n",
      "I0000 00:00:1717694244.984311    2604 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "%timeit softmax_with_jit(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea79058-caea-41d5-b33b-dc801c619421",
   "metadata": {},
   "source": [
    "### PyTorch jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1972676-22c1-474b-8a81-f7f5d9f50417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define the softmax function\n",
    "def softmax(logits):\n",
    "    exp_logits = torch.exp(logits - torch.max(logits))\n",
    "    return exp_logits / torch.sum(exp_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8293fac0-eda2-418b-9d25-090f9e857256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random logits\n",
    "logits = torch.randn(1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f241c29e-2186-42de-924a-2938d2798a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.4 µs ± 1.2 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Measure time without JIT\n",
    "%timeit softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a501b59-1273-4334-b6e6-001095cf19aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def softmax_jit(logits):\n",
    "    exp_logits = torch.exp(logits - torch.max(logits))\n",
    "    return exp_logits / torch.sum(exp_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cd903fe-e019-41f2-acd6-f611de3a06e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.4 µs ± 1.4 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit softmax_jit(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c799536-3cbd-4a14-8c69-c9ff90fa5b6e",
   "metadata": {},
   "source": [
    "## Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e1d53b-36f9-47ee-8f1f-0923cd74a34d",
   "metadata": {},
   "source": [
    "Let's consider a simple polinomial function: x^2+2x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4943493-75c8-4118-a497-89f3fbf9c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2 + 2*x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6226859-519b-43b1-a34f-d469172cec81",
   "metadata": {},
   "source": [
    "### Jax Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c6da409-431e-419b-a771-be83f2ae9f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of f(x) in Jax: 8.0\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "x = 3.0\n",
    "grad_fn = jax.grad(f)\n",
    "grad = grad_fn(x)\n",
    "\n",
    "print(\"Gradient of f(x) in Jax:\",grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4bdbd1-06f0-4006-b2a4-67b34c7274c2",
   "metadata": {},
   "source": [
    "### Tensorflow GradientTape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0edd1f3-c46d-4835-b3f2-31746d4000e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of f(x) in TensorFlow: 8.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = f(x)\n",
    "grad = tape.gradient(y, x)\n",
    "\n",
    "print(\"Gradient of f(x) in TensorFlow:\",grad.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa71ad0-b65d-4132-9a6b-5aa8a88d5701",
   "metadata": {},
   "source": [
    "### PyTorch Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29a7ac84-51ff-4493-a0a3-704b2d2f739e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of f(x) in PyTorch: 8.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = f(x)\n",
    "y.backward()\n",
    "\n",
    "print(\"Gradient of f(x) in PyTorch:\",x.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a04292fa-9ab3-485e-8af9-03a2af70daa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed in JAX: 0.13792634010314941\n",
      "Time elapsed in TensorFlow: 0.00521397590637207\n",
      "Time elapsed in PyTorch: 0.00021648406982421875\n"
     ]
    }
   ],
   "source": [
    "# Measure time for JAX - without using jit\n",
    "def jax_time():\n",
    "    x = 3.0\n",
    "    grad_fn = jax.grad(f)\n",
    "    start_time = time.time()\n",
    "    with jax.default_device(jax.devices('cpu')[0]):\n",
    "    #with jax.default_device(jax.devices('gpu')[0]):\n",
    "        grad = grad_fn(x)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "time_jax = jax_time()\n",
    "\n",
    "# Measure time for TensorFlow\n",
    "def tensorflow_time():\n",
    "    x = tf.Variable(3.0)\n",
    "    start_time = time.time()\n",
    "    with tf.device('/CPU:0'):\n",
    "    #with tf.device('/GPU:0'):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y = f(x)\n",
    "    grad = tape.gradient(y, x)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "    \n",
    "time_tf=tensorflow_time()\n",
    "\n",
    "# Measure time for PyTorch\n",
    "def pytorch_time():\n",
    "    device = torch.device('cpu')\n",
    "    #device = torch.device('cuda')\n",
    "    x = torch.tensor(3.0, requires_grad=True,device=device)\n",
    "    start_time = time.time()\n",
    "    y = f(x)\n",
    "    y.backward()\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "time_pt=pytorch_time()\n",
    "\n",
    "print(\"Time elapsed in JAX:\", time_jax)\n",
    "print(\"Time elapsed in TensorFlow:\", time_tf)\n",
    "print(\"Time elapsed in PyTorch:\", time_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e58eb3-ada5-4406-8db9-b3c115826b42",
   "metadata": {},
   "source": [
    "## Automatic Vectorization VMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b80f61-9820-4b39-a0b0-850d1bf65182",
   "metadata": {},
   "source": [
    "It allows you to apply a function to each element in a batch of inputs without manually writing loops. This leads to more concise and often more efficient code by leveraging JAX's underlying compilation and optimization.\n",
    "\n",
    "Basic usage considering simple sum of arrays 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea5b9b7-c768-4962-81d4-e508d99e141a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[ 1,  3],\n",
       "        [ 4, -1]], dtype=int32),\n",
       " Array([[11,  7],\n",
       "        [-2,  5]], dtype=int32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "#Definition of samples arrays\n",
    "a=jnp.array(([1,3],[4,-1]))\n",
    "b=jnp.array(([11,7],[-2,5]))\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0188dea0-f788-4952-a20d-d10572ba9a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[12, 10],\n",
       "       [ 2,  4]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classical add operation\n",
    "jnp.add(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc255623-48ca-495a-9fc8-9c35d9d11f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[12, 10],\n",
       "       [ 2,  4]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add operation using vmap row by row and the output is given by row\n",
    "jax.vmap(jnp.add,in_axes=(0,0),out_axes=0)(a,b)\n",
    "\n",
    "## [ [ (1+11) , (3+7) ]\n",
    "##   [ (4-2), (-1+5) ]\n",
    "## ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb481c2a-5507-4ff9-972a-2ae51eab6907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[12,  2],\n",
       "       [10,  4]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add operation using vmap row by row and the output is given by column\n",
    "jax.vmap(jnp.add,in_axes=(0,0),out_axes=1)(a,b)\n",
    "\n",
    "## [ [ (1+11) , (4-2) ] \n",
    "##   [ (3+7), (-1+5) ]\n",
    "## ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4040714-fae0-44f0-bcb5-4c2cc40e1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.vmap(jnp.add,in_axes=(1,0),out_axes=0)(a,b)\n",
    "\n",
    "a=jnp.array(([1,3],[4,-1]))\n",
    "b=jnp.array(([11,7],[-2,5]))\n",
    "\n",
    "## [ [ (1+11) , (4+7) ] #Col of a + corr. row of b\n",
    "##   [ (3+7), (-1+5) ]\n",
    "## ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdaa612-d994-4b91-a633-21fedd39cb6f",
   "metadata": {},
   "source": [
    "### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dd1022-eb37-4f3d-a351-5def33c5d54e",
   "metadata": {},
   "source": [
    "In this example, it calculates the square of each element in the array passed as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c186e6de-d4e1-4adb-8752-7c4d42a1cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import vmap\n",
    "\n",
    "def square(x):\n",
    "  return jnp.square(x)\n",
    "    \n",
    "def square_numpy(arr):\n",
    "    return np.square(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89a1b200-9dc9-478c-a188-b4fb61d34e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numPy_numbers = np.arange(1000)\n",
    "jax_numbers=jnp.arange(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baec3081-1714-4f09-8425-7dff52f69602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken using standard loop: 0.37405 seconds\n",
      "Time taken using numpy: 0.00028 seconds\n",
      "Time taken using vmap: 0.00008 seconds\n"
     ]
    }
   ],
   "source": [
    "# Apply the square function using a standard loop: classical way.\n",
    "start_time = time.time()\n",
    "squared_numbers_loop = [square(x) for x in jax_numbers]\n",
    "loop_time = time.time() - start_time\n",
    "print(f\"Time taken using standard loop: {loop_time:.5f} seconds\")\n",
    "\n",
    "#Apply the square function using numpy function.\n",
    "start_time = time.time()\n",
    "result = square_numpy(numPy_numbers)\n",
    "end_time=time.time()\n",
    "numpy_end_time=end_time-start_time\n",
    "print(f\"Time taken using numpy: {numpy_end_time:.5f} seconds\")\n",
    "\n",
    "\n",
    "# Apply the vectorized function\n",
    "start_time = time.time()\n",
    "# Vectorize the square function using vmap\n",
    "vectorized_square = jax.vmap(square)\n",
    "vmap_time = time.time() - start_time\n",
    "print(f\"Time taken using vmap: {vmap_time:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856914f7-11d6-49c1-99ce-4cd4ad906317",
   "metadata": {},
   "source": [
    "### A other example : matrix-vector multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd1b2af4-ba7f-43a9-bccb-3d0bd4f7ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define matrix-vector multiplication function\n",
    "@jax.jit\n",
    "def matrix_vector_multiplication(matrix, vector):\n",
    "    return jnp.dot(matrix, vector)\n",
    "\n",
    "def matrix_vector_multiplication_numpy(matrix, vector):\n",
    "    return np.dot(matrix, vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb5bccf-c393-4db3-bf5f-88522d2f0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the matrix size\n",
    "matrix_size = 10000  # For example, change this to your desired size\n",
    "\n",
    "# Create an incremental matrix  and vector for jax\n",
    "matrix_jax = jnp.arange(matrix_size * matrix_size).reshape((matrix_size, matrix_size))\n",
    "vector_jax = jnp.arange(matrix_size).reshape((matrix_size, 1))\n",
    "\n",
    "matrix_np=np.arange(matrix_size * matrix_size).reshape((matrix_size, matrix_size))\n",
    "vector_np=np.arange(matrix_size).reshape((matrix_size,1))\n",
    "\n",
    "print(\"Incremental Matrix:\")\n",
    "print(matrix_jax)\n",
    "\n",
    "print(\"\\nIncremental Vector:\")\n",
    "print(vector_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ee5c72d-2eda-41bb-b0ed-6578e45371ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken using vmap: 0.045346975326538086\n"
     ]
    }
   ],
   "source": [
    "# Use vmap to perform batched matrix-vector multiplication\n",
    "matvec_vmap = jax.vmap(matrix_vector_multiplication, in_axes=(0, None))\n",
    "\n",
    "start_time=time.time()\n",
    "result = matvec_vmap(matrix_jax, vector_jax)\n",
    "end_time=time.time()\n",
    "\n",
    "tot_time=end_time-start_time\n",
    "print(f\"Time taken using vmap: {tot_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cd6b6cb-16a9-4bd9-99fc-eb248b8ed205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken using numpy: 0.07039618492126465\n"
     ]
    }
   ],
   "source": [
    "# Apply the function directly\n",
    "start_time=time.time()\n",
    "result = matrix_vector_multiplication_numpy(matrix_np, vector_np)\n",
    "end_time=time.time()\n",
    "tot_time=end_time-start_time\n",
    "\n",
    "print(f\"Time taken using numpy: {tot_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8047a1c1-7bbe-462d-bc49-df6d199dd934",
   "metadata": {},
   "source": [
    "## Automatic Parallelization PMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a256234b-d9e7-4b89-a656-fbc2d3a8ea3e",
   "metadata": {},
   "source": [
    "Pmap is another transformation that enables to replicate the computation into multiple cores or devices and execute them in parallel(p in pmap stands for parallel).\n",
    "\n",
    "To have a real benefit from this functionality you need multiple devices. \n",
    "Unless you have multiple GPUs you should restart the notebook an run the following snippets - to use your CPU multiple cores.\n",
    "Suggestion: don't put num_core>your_max_hardware_num_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "759ef81d-8f17-48ce-bc96-81b840fcf620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0),\n",
       " CpuDevice(id=1),\n",
       " CpuDevice(id=2),\n",
       " CpuDevice(id=3),\n",
       " CpuDevice(id=4),\n",
       " CpuDevice(id=5),\n",
       " CpuDevice(id=6),\n",
       " CpuDevice(id=7),\n",
       " CpuDevice(id=8),\n",
       " CpuDevice(id=9),\n",
       " CpuDevice(id=10),\n",
       " CpuDevice(id=11)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['JAX_PLATFORM_NAME'] = 'cpu'\n",
    "num_core= os.cpu_count()\n",
    "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count='+str(num_core)\n",
    "import jax\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4bfc84c-4798-480a-aa95-27aa69e90286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import pmap\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8581b2a-c2de-4346-a83c-2279713d6cfa",
   "metadata": {},
   "source": [
    "### A simple operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec485b00-612e-424c-b3cf-54ecdf3f4fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.arange(3 * 2 * 2.).reshape((3, 2, 2))\n",
    "y = jnp.arange(3 * 2 * 2.).reshape((3, 2, 2)) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a9187a-0291-44e5-bdf5-d163c6c5dfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken using pmap: 0.030210494995117188\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "out = pmap(jnp.dot)(x, y)  \n",
    "end_time=time.time()\n",
    "\n",
    "tot_time=end_time-start_time\n",
    "\n",
    "print(f\"Time taken using pmap: {tot_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93abf1d6-109d-498a-9248-37a68699c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken without using pmap: 0.26958250999450684\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "out = jnp.dot(x, y)  \n",
    "end_time=time.time()\n",
    "\n",
    "tot_time=end_time-start_time\n",
    "\n",
    "print(f\"Time taken without using pmap: {tot_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1f95e-ef7d-4edb-bf45-1442e81aea68",
   "metadata": {},
   "source": [
    "### Matrix-matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "186a99ab-2517-4c4e-b7d6-b131e994f3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[0., 1., 2.],\n",
       "        [3., 4., 5.],\n",
       "        [6., 7., 8.]], dtype=float32),\n",
       " Array([[0., 1., 2.],\n",
       "        [3., 4., 5.],\n",
       "        [6., 7., 8.]], dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define two matrices in this way\n",
    "\n",
    "#Matrix used: change dimension to see difference in time\n",
    "a = jnp.arange(9, dtype=jnp.float32).reshape(3, 3)\n",
    "b = jnp.arange(9, dtype=jnp.float32).reshape(3, 3)\n",
    "\n",
    "#a= jnp.arange(10000 * 10000, dtype=jnp.float32).reshape(10000, 10000)\n",
    "#b= jnp.arange(10000 * 10000, dtype=jnp.float32).reshape(10000, 10000)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556baaeb-43f6-4c09-98c1-45bda23ec712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for matrix multiplication\n",
    "def matmul(a, b):\n",
    "    return jnp.dot(a, b)\n",
    "\n",
    "@jax.jit\n",
    "def parallel_matmul(a, b):\n",
    "    return matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b482d4d8-58fd-435a-a92f-09f2506de3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[7.8120318e+16, 7.8120318e+16, 7.8120318e+16, ..., 7.8125017e+16,\n",
       "        7.8125017e+16, 7.8125017e+16],\n",
       "       [1.9530312e+17, 1.9530312e+17, 1.9530312e+17, ..., 1.9531719e+17,\n",
       "        1.9531719e+17, 1.9531719e+17],\n",
       "       [3.1248591e+17, 3.1248595e+17, 3.1248595e+17, ..., 3.1250938e+17,\n",
       "        3.1250938e+17, 3.1250938e+17],\n",
       "       ...,\n",
       "       [1.7574687e+21, 1.7574687e+21, 1.7574687e+21, ..., 1.7576093e+21,\n",
       "        1.7576093e+21, 1.7576093e+21],\n",
       "       [1.7575859e+21, 1.7575859e+21, 1.7575859e+21, ..., 1.7577266e+21,\n",
       "        1.7577266e+21, 1.7577266e+21],\n",
       "       [1.7577031e+21, 1.7577031e+21, 1.7577031e+21, ..., 1.7578436e+21,\n",
       "        1.7578436e+21, 1.7578436e+21]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matmul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "540e5f35-9d4a-4429-acf4-23707e45a1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken using pmap: 0.000310 seconds\n"
     ]
    }
   ],
   "source": [
    "# Prepare the matrices for pmap by adding a leading axis. \n",
    "# This op. is needed because pmap maps the function over leading axis on the first axes, \n",
    "# and you have to mantain an extra axis to make it work\n",
    "a_parallel = jnp.array([a])  # Shape (1, 3, 3)\n",
    "b_parallel = jnp.array([b])  # Shape (1, 3, 3)\n",
    "\n",
    "# Apply pmap to the parallel matrix multiplication function\n",
    "matmul_parallel = pmap(parallel_matmul)\n",
    "\n",
    "# Warm-up to ensure JAX is initialized\n",
    "dummy_result = matmul_parallel(a_parallel, b_parallel)\n",
    "\n",
    "# Measure time for parallel computation using pmap\n",
    "start_time = time.time()\n",
    "result_parallel = matmul_parallel(a_parallel, b_parallel)\n",
    "\n",
    "# Remove the extra axis\n",
    "result_parallel = result_parallel[0]  \n",
    "\n",
    "end_time = time.time()\n",
    "tot_time_parallel = end_time - start_time\n",
    "\n",
    "print(f\"Time taken using pmap: {tot_time_parallel} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1adc53b1-0b10-4020-be58-a38892a41552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken without using pmap: 0.014169692993164062 seconds\n"
     ]
    }
   ],
   "source": [
    "# Measure time for non-parallel computation\n",
    "start_time = time.time()\n",
    "result_no_pmap = matmul(a, b)\n",
    "end_time = time.time()\n",
    "tot_time_no_pmap = end_time - start_time\n",
    "\n",
    "print(f\"Time taken without using pmap: {tot_time_no_pmap} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48a06db1-06f1-4758-9608-79232ea783ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix a:\n",
      " [[0. 1. 2.]\n",
      " [3. 4. 5.]\n",
      " [6. 7. 8.]]\n",
      "Matrix b:\n",
      " [[0. 1. 2.]\n",
      " [3. 4. 5.]\n",
      " [6. 7. 8.]]\n",
      "Result of matrix mult. using pmap:\n",
      " [[ 15.  18.  21.]\n",
      " [ 42.  54.  66.]\n",
      " [ 69.  90. 111.]]\n",
      "Result of matrix mult. without using pmap:\n",
      " [[ 15.  18.  21.]\n",
      " [ 42.  54.  66.]\n",
      " [ 69.  90. 111.]]\n"
     ]
    }
   ],
   "source": [
    "#Check results\n",
    "print(\"Matrix a:\\n\", a)\n",
    "print(\"Matrix b:\\n\", b)\n",
    "print(\"Result of matrix mult. using pmap:\\n\", result_parallel)\n",
    "print(\"Result of matrix mult. without using pmap:\\n\", result_no_pmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
