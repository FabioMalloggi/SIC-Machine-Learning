{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Exercise #0704b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to force use of CPU.\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "#Suppress TF warnings\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Multi-layer neural network to recognize the handswritten digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist             # MNIST handwritten digits data!\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Download the MNIST data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verbosity_saved = tf.logging.get_verbosity()                                           # Save the current verbosity lebel if needed.\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)                                  # Set the verbosity lebel high so that most warnings are ignored. \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()                                 # Download the data.\n",
    "type(x_train)                                                                            # Check the type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Take a look at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data X shape: (60000, 28, 28)\n",
      "Training data y shape: (60000,)\n",
      "Training data cases:  60000\n",
      "\n",
      "\n",
      "Testing data X shape: (10000, 28, 28)\n",
      "Testing data y shape: (10000,)\n",
      "Testing data cases:  10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data X shape: {}\".format((x_train).shape))\n",
    "print(\"Training data y shape: {}\".format((y_train).shape))\n",
    "print(\"Training data cases: \",len(x_train))\n",
    "print(\"\\n\")\n",
    "print(\"Testing data X shape: {}\".format((x_test).shape))\n",
    "print(\"Testing data y shape: {}\".format((y_test).shape))\n",
    "print(\"Testing data cases: \",len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i_image= 1                                                    # Image index. You can change it at will.\n",
    "a_single_image = x_train[i_image].reshape(28,28)              #  Reshape as a 2D array.\n",
    "plt.imshow(1-a_single_image, cmap='gist_gray')                #  Display as grayscale image.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN : 0\n",
      "MAX : 255\n"
     ]
    }
   ],
   "source": [
    "# Check for the minimum and maximum pixel value.\n",
    "# The data has been min-max-scaled already!\n",
    "print(\"MIN : {}\".format(a_single_image.min()))                 \n",
    "print(\"MAX : {}\".format(a_single_image.max())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Do the necessary definitions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30                                # Size of each (mini) batch.\n",
    "n_epochs  = 20                             # Number of epochs.\n",
    "learn_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 09:10:47.274658: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# We are building a multi-layer neural network. Thus, several sets of (b,W) required.\n",
    "# Parameters that connect the input layer with the first hidden layer. \n",
    "W1 = tf.Variable(tf.random.normal([784,30],0,1))   # Input = 784 nodes, Output = 30 nodes.   \n",
    "b1 = tf.Variable(tf.random.normal([30],0,1))     \n",
    "# Parameters that connect the first hidden layer with the second hidden layer.\n",
    "W2 = tf.Variable(tf.random.normal([30,15],0,1))    # Input = 30 nodes, Output = 15 nodes (the same as the number of output nodes at the previous layer).\n",
    "b2 = tf.Variable(tf.random.normal([15],0,1)) \n",
    "# Parameters that connect the second hidden layer with the output layer.\n",
    "W3 = tf.Variable(tf.random.normal([15,10],0,1))    # Input = 15 nodes, Output = 10 nodes (the same as the number of output nodes at the previous layer).\n",
    "b3 = tf.Variable(tf.random.normal([10],0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_ph = tf.placeholder(tf.float32, [None, 784])   # Indetermined number of cases (observations). Input nodes = 784.\n",
    "#y_ph = tf.placeholder(tf.float32,[None,10])      # The response variable has been one-hot-encoded. There are 10 output nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A multi-layer model.\n",
    "# As before, the Softmax activation at the output layer is optional. \n",
    "#hidden1 = tf.nn.sigmoid(tf.matmul(X_ph,W1) + b1)\n",
    "#hidden2 = tf.nn.sigmoid(tf.matmul(hidden1,W2) + b2)\n",
    "#y_model =  tf.matmul(hidden2, W3) + b3\n",
    "\n",
    "def model(X):\n",
    "    hidden1 = tf.nn.sigmoid(tf.matmul(X, W1) + b1)\n",
    "    hidden2 = tf.nn.sigmoid(tf.matmul(hidden1, W2) + b2)\n",
    "    y_model =  tf.matmul(hidden2, W3) + b3\n",
    "    return y_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss  = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_ph, logits=y_model))   # loss = Cross Entropy. \n",
    "def loss_fn(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = tf.train.AdamOptimizer(learning_rate = learn_rate)     # A better optimizer.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate)      # A better optimizer.\n",
    "\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate = learn_rate)       # A basic optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape data to match the shape expected by the neural network\n",
    "x_train = x_train.reshape((-1, 784))\n",
    "x_test = x_test.reshape((-1, 784))\n",
    "\n",
    "y_train = tf.one_hot(y_train, depth=10)  # Assuming there are 10 classes in your dataset\n",
    "y_test = tf.one_hot(y_test, depth=10)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size=len(x_train)).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Training and Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step = 1\n",
      "Step = 1\n",
      "Step = 2\n",
      "Step = 2\n",
      "Step = 3\n",
      "Step = 3\n",
      "Step = 4\n",
      "Step = 4\n",
      "Step = 5\n",
      "Step = 5\n",
      "Step = 6\n",
      "Step = 6\n",
      "Step = 7\n",
      "Step = 7\n",
      "Step = 8\n",
      "Step = 8\n",
      "Step = 9\n",
      "Step = 9\n",
      "Step = 10\n",
      "Step = 10\n",
      "Step = 11\n",
      "Step = 11\n",
      "Step = 12\n",
      "Step = 12\n",
      "Step = 13\n",
      "Step = 13\n",
      "Step = 14\n",
      "Step = 14\n",
      "Step = 15\n",
      "Step = 15\n",
      "Step = 16\n",
      "Step = 16\n",
      "Step = 17\n",
      "Step = 17\n",
      "Step = 18\n",
      "Step = 18\n",
      "Step = 19\n",
      "Step = 19\n",
      "Step = 20\n",
      "Step = 20\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_epochs):\n",
    "    # Training\n",
    "    for batch_X, batch_y in train_dataset:                        # Sample a batch!\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(batch_X)\n",
    "            loss_value = loss_fn(batch_y, predictions)\n",
    "        gradients = tape.gradient(loss_value, [W1, b1, W2, b2, W3, b3])\n",
    "        optimizer.apply_gradients(zip(gradients, [W1, b1, W2, b2, W3, b3]))\n",
    "        \n",
    "    if (i + 1) % 2000 == 0: print(\"Step = {}\".format(i + 1))                   # Print the step number at every multiple of 2000.\n",
    "    \n",
    "# Testing\n",
    "correct_predictions = tf.equal(tf.argmax(y_test, axis=1), tf.argmax(model(x_test), axis=1))   # In argmax(), axis=1 means horizontal direction.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))                           # Recast the Boolean as float32 first. Then calculate the mean.\n",
    "accuracy_value = accuracy.numpy()                                                             # Use all of the testing data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the testing result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.958\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = {:5.3f}\".format(accuracy_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 09:38:20.868201: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-15 09:38:21.472462: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the verbosity level of TensorFlow to ignore most warnings\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 09:38:34.377961: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.398625: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.398667: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.400705: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.400744: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.400772: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.549467: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.549523: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.549531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-15 09:38:34.549565: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-15 09:38:34.549584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4699 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Normalize pixel values to the range [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape data to match the shape expected by the neural network\n",
    "x_train = x_train.reshape((-1, 784))\n",
    "x_test = x_test.reshape((-1, 784))\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.one_hot(y_train, depth=10)\n",
    "y_test = tf.one_hot(y_test, depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size and number of epochs\n",
    "batch_size = 30\n",
    "n_epochs = 20\n",
    "learn_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(30, activation='sigmoid', input_shape=(784,)),\n",
    "    keras.layers.Dense(15, activation='sigmoid'),\n",
    "    keras.layers.Dense(10)  # No activation for the output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size=len(x_train)).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715758753.853088    3007 service.cc:145] XLA service 0x7fa644005cb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1715758753.853135    3007 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce GTX 1060 6GB, Compute Capability 6.1\n",
      "2024-05-15 09:39:13.870501: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-15 09:39:13.940613: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  96/2000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4205 - loss: 1.8778"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1715758755.191442    3007 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8273 - loss: 0.6281\n",
      "Epoch 2/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.1956\n",
      "Epoch 3/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1729\n",
      "Epoch 4/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9545 - loss: 0.1498\n",
      "Epoch 5/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9571 - loss: 0.1439\n",
      "Epoch 6/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9565 - loss: 0.1419\n",
      "Epoch 7/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9615 - loss: 0.1234\n",
      "Epoch 8/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9616 - loss: 0.1268\n",
      "Epoch 9/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9656 - loss: 0.1156\n",
      "Epoch 10/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9668 - loss: 0.1084\n",
      "Epoch 11/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.1083\n",
      "Epoch 12/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9670 - loss: 0.1078\n",
      "Epoch 13/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.1039\n",
      "Epoch 14/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.1019\n",
      "Epoch 15/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.1029\n",
      "Epoch 16/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.0937\n",
      "Epoch 17/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.0954\n",
      "Epoch 18/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.0895\n",
      "Epoch 19/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0955\n",
      "Epoch 20/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9734 - loss: 0.0860\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.1652\n",
      "Test Accuracy: 0.9567999839782715\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_dataset, epochs=n_epochs, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
