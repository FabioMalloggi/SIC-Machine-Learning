{"cells":[{"cell_type":"markdown","metadata":{"id":"n6iT2f6FrgnT"},"source":["## Coding Exercise #0706"]},{"cell_type":"code","source":["# tensorflow 2.15.0 is already installed, it must be uninstalled first\n","!pip uninstall tensorflow -y\n","!pip uninstall keras -y\n","!pip uninstall tf-keras -y\n","!pip install tensorflow\n","# !pip install --upgrade keras //automatically done installing tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6dU-_aVlV16","executionInfo":{"status":"ok","timestamp":1715866115087,"user_tz":-120,"elapsed":100374,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}},"outputId":"04007345-f353-4716-bdc1-6c75090fe632"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.15.0\n","Uninstalling tensorflow-2.15.0:\n","  Successfully uninstalled tensorflow-2.15.0\n","Found existing installation: keras 2.15.0\n","Uninstalling keras-2.15.0:\n","  Successfully uninstalled keras-2.15.0\n","Found existing installation: tf_keras 2.15.1\n","Uninstalling tf_keras-2.15.1:\n","  Successfully uninstalled tf_keras-2.15.1\n","Collecting tensorflow\n","  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Collecting h5py>=3.10.0 (from tensorflow)\n","  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Collecting ml-dtypes~=0.3.1 (from tensorflow)\n","  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n","Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n","  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras>=3.0.0 (from tensorflow)\n","  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n","Collecting namex (from keras>=3.0.0->tensorflow)\n","  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n","Collecting optree (from keras>=3.0.0->tensorflow)\n","  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n","Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.2.0\n","    Uninstalling ml-dtypes-0.2.0:\n","      Successfully uninstalled ml-dtypes-0.2.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.9.0\n","    Uninstalling h5py-3.9.0:\n","      Successfully uninstalled h5py-3.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","Successfully installed h5py-3.11.0 keras-3.3.3 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1\n"]}]},{"cell_type":"markdown","metadata":{"id":"ctl-vJDQrgnU"},"source":["### 1. Convolutional Neural Network (grayscale images):"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Gr2RcLhTrgnU","executionInfo":{"status":"ok","timestamp":1715866119690,"user_tz":-120,"elapsed":4616,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"VxZTcGW1rgnU"},"source":["#### 1.1. Download the MNIST data:"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"iapRbguLrgnV","executionInfo":{"status":"ok","timestamp":1715866120687,"user_tz":-120,"elapsed":1001,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2f3c9b87-94e2-4174-8da8-39ebb8442960"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}],"source":["(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = tf.keras.datasets.mnist.load_data()\n","\n","# for mnist_train_images and mnist_test_images shape is already = [batch_size, in_height, in_width, in_channels]\n","mnist_train_images = mnist_train_images.astype('float32') / 255\n","mnist_test_images = mnist_test_images.astype('float32') / 255\n","\n","mnist_train_images = np.expand_dims(mnist_train_images, -1)\n","mnist_test_images = np.expand_dims(mnist_test_images, -1)\n","\n","mnist_train_labels = tf.keras.utils.to_categorical(mnist_train_labels, 10)          # one-hot encoding labels\n","mnist_test_labels = tf.keras.utils.to_categorical(mnist_test_labels, 10)"]},{"cell_type":"markdown","metadata":{"id":"PvJloi-4rgnV"},"source":["#### 1.2. Take a look at the dataset:"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"YaOpVOUqrgnV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715866120688,"user_tz":-120,"elapsed":4,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}},"outputId":"1de82643-4d34-4507-abd1-e150fc022056"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training data X shape: (60000, 28, 28, 1)\n","Training data y shape: (60000, 10)\n","Training data cases: 60000\n","\n","\n","Testing data X shape: (10000, 28, 28, 1)\n","Testing data y shape: (10000, 10)\n","Testing data cases: 10000\n"]}],"source":["print(\"Training data X shape: {}\".format((mnist_train_images).shape))\n","print(\"Training data y shape: {}\".format((mnist_train_labels).shape))\n","print(\"Training data cases: {}\".format(mnist_train_images.shape[0]))\n","print(\"\\n\")\n","print(\"Testing data X shape: {}\".format((mnist_test_images).shape))\n","print(\"Testing data y shape: {}\".format((mnist_test_labels).shape))\n","print(\"Testing data cases: {}\".format(mnist_test_images.shape[0]))"]},{"cell_type":"markdown","metadata":{"id":"luVrPJtnrgnV"},"source":["Visualization."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"pFCI0ju-rgnV","colab":{"base_uri":"https://localhost:8080/","height":430},"executionInfo":{"status":"ok","timestamp":1715866121171,"user_tz":-120,"elapsed":486,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}},"outputId":"549d76f2-fe0d-473f-8964-c0abada0ea18"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["i_image= 1                                                      # Image index. You can change it at will.\n","a_single_image = mnist_train_images[i_image].reshape(28,28)     #  Reshape as a 2D array.\n","plt.imshow(1-a_single_image, cmap='gist_gray')                  #  Display as grayscale image.\n","plt.show()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"pLKdLIQwrgnV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715866121171,"user_tz":-120,"elapsed":6,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}},"outputId":"6b87146e-1a24-4516-f95c-fd56467e7645"},"outputs":[{"output_type":"stream","name":"stdout","text":["MIN : 0.0\n","MAX : 1.0\n"]}],"source":["# Check for the minimum and maximum pixel value.\n","# The data has been min-max-scaled already!\n","print(\"MIN : {}\".format(a_single_image.min()))\n","print(\"MAX : {}\".format(a_single_image.max()))"]},{"cell_type":"markdown","metadata":{"id":"lFH1XkHUrgnV"},"source":["#### 1.3. Define the hyperparameters:"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"qqQIqscPrgnW","executionInfo":{"status":"ok","timestamp":1715866121171,"user_tz":-120,"elapsed":5,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}}},"outputs":[],"source":["batch_size = 8\n","n_epochs  = 10001\n","learn_rate = 0.0001\n","drop_prob = 0.5                                     # For the dropout layer."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"i-7dug6mrgnW","executionInfo":{"status":"ok","timestamp":1715866121171,"user_tz":-120,"elapsed":4,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}}},"outputs":[],"source":["#X = tf.placeholder(tf.float32, [None, 784])      # 'None' means any number of rows (observations or batch_size)\n","#y = tf.placeholder(tf.float32,[None, 10])\n","#drop_prob_ph = tf.placeholder(tf.float32)           # The drop probability at the dropout layer is a hyperparameter.\n","# X need no reshape in order to be fed into the conv2D function."]},{"cell_type":"markdown","metadata":{"id":"qWkcGAoTrgnW"},"source":["#### 1.4. Define the Variables:"]},{"cell_type":"markdown","metadata":{"id":"ggKyyQ_vrgnW"},"source":["The configuration of the first convolution layer is as following:\n","- Kernel height = 5.\n","- Kernel width = 5.\n","- In_chanels = 1 (gray scale).\n","- Out_channels = 32 (number of feature maps)."]},{"cell_type":"markdown","metadata":{"id":"tNl-aIOyrgnW"},"source":["We need Variables with the folllowing shapes:\n","- Shape of the weight matrix = [kernel_height, kernel_width, in_channels, out_channels].\n","- Shape of the bias = [out_channels]."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"_AW1rUHzrgnW","executionInfo":{"status":"ok","timestamp":1715866121171,"user_tz":-120,"elapsed":4,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}}},"outputs":[],"source":["# Variables are defined according to the specifications mentioned above.\n","W1 = tf.Variable(initial_value=tf.random.normal([5,5,1,32], mean=0, stddev=0.1))\n","b1 = tf.Variable(initial_value=tf.fill([32], 0.1))"]},{"cell_type":"markdown","metadata":{"id":"sSeQsYBMrgnW"},"source":["The configuration of the second convolution layer is as following:\n","- Kernel height = 5.\n","- Kernel width = 5.\n","- In_chanels = 32 (out_channels from the previous convolution layer).\n","- Out_channels = 64 (number of feature maps)."]},{"cell_type":"markdown","metadata":{"id":"4_ZJe_LbrgnW"},"source":["Again, we need Variables with the folllowing shapes:\n","- Shape of the weight matrix = [kernel_height, kernel_width, in_channels, out_channels].\n","- Shape of the bias = [out_channels]."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"JfbO7LYBrgnW","executionInfo":{"status":"ok","timestamp":1715866121171,"user_tz":-120,"elapsed":4,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}}},"outputs":[],"source":["# Variables are defined according to the specifications mentioned above.\n","W2 = tf.Variable(initial_value=tf.random.normal([5,5,32,64], mean=0, stddev=0.1))\n","b2 = tf.Variable(initial_value=tf.fill([64], 0.1))"]},{"cell_type":"markdown","metadata":{"id":"eys_eGglrgnX"},"source":["We do the following considerations for the flattened fully connected layer:\n","- We will apply convolution twice with padding and there will be no image size reduction.\n","- We will also apply max pooling twice with stride = 2 (vertically and horizontally).\n","- At each max pooling with stride = 2, the image size is halved. Thus, (28/2)/2 = 7 will be the size (vertical and horizontal) of the resulting final image.   \n","- In the previous layer there were 64 output channels (feature maps).\n","- Considering all these facts, there should be 7x7x64 = 3136 nodes in the flattened layer.\n","- Finally, we will shrink the output from this layer to 1024."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"_5cASygVrgnX","executionInfo":{"status":"ok","timestamp":1715866121494,"user_tz":-120,"elapsed":327,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}}},"outputs":[],"source":["# Variables are defined according to the specifications mentioned above.\n","W3 = tf.Variable(initial_value=tf.random.normal([3136,1024], mean=0, stddev=0.1))\n","b3 = tf.Variable(initial_value=tf.fill([1024], 0.1))"]},{"cell_type":"markdown","metadata":{"id":"l2XDEdpDrgnX"},"source":["We do the following considerations for the final output layer:\n","- There are 1024 nodes to match with the output from the previous layer.\n","- We should shrink the output once more because there are 10 different labels (digits 0~9)."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"MQryn4g4rgnX","executionInfo":{"status":"ok","timestamp":1715866121495,"user_tz":-120,"elapsed":3,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}}},"outputs":[],"source":["# Variables are defined according to the specifications mentioned above.\n","W4 = tf.Variable(initial_value=tf.random.normal([1024,10], mean=0, stddev=0.1))\n","b4 = tf.Variable(initial_value=tf.fill([10], 0.1))"]},{"cell_type":"markdown","metadata":{"id":"GO7J-OKRrgnX"},"source":["#### 1.5. Define the deep learning model (CNN):"]},{"cell_type":"markdown","metadata":{"id":"Sj2b1FQZrgnX"},"source":["Explanation of the arguments:\n","- padding = 'SAME' to apply a padding. padding = 'VALID' to apply no padding.\n","- ksize = [1, kernel_height, kernel_width, 1]\n","- strides = [1, stride_vertical, stride_horizontal,1]"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"YdjfMv5ErgnX","executionInfo":{"status":"ok","timestamp":1715866121495,"user_tz":-120,"elapsed":3,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}}},"outputs":[],"source":["@tf.function\n","def model(X, drop_probability):\n","  # 1st Convolution layer.\n","  y1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME') + b1\n","  conv1 = tf.nn.relu(y1)                             # Apply the ReLu activation function.\n","  # 1st Pooling layer.\n","  pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n","\n","  # 2nd Convolution layer.\n","  y2 = tf.nn.conv2d(pool1, W2, strides=[1, 1, 1, 1], padding='SAME') + b2\n","  conv2 = tf.nn.relu(y2)                            # Apply the ReLu activation function.\n","  # 2nd Pooling layer.\n","  pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n","\n","  # Flattened full layer.\n","  conv2_flattened = tf.reshape(pool2, [-1,3136])   # 7x7x64 = 3136.\n","  y3 = tf.matmul(conv2_flattened, W3) + b3\n","  full_layer = tf.nn.relu(y3)                      # Apply the ReLu activation function.\n","\n","  # Dropout layer.\n","  dropout_layer = tf.nn.dropout(full_layer, rate = drop_probability)\n","\n","  # Output layer.\n","  y_model = tf.matmul(dropout_layer, W4) + b4      # No activation function. Softmax at the output layer is optional.\n","  return y_model"]},{"cell_type":"markdown","metadata":{"id":"cuLmhVRUrgnY"},"source":["#### 1.6. Define the loss function and the optimizer:"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"yVqjalMQrgnY","executionInfo":{"status":"ok","timestamp":1715866121495,"user_tz":-120,"elapsed":3,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}}},"outputs":[],"source":["def loss_fn(y_true, y_pred):\n","  return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))   # loss = Cross Entropy."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"_cSb88E1rgnY","executionInfo":{"status":"ok","timestamp":1715866121495,"user_tz":-120,"elapsed":3,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}}},"outputs":[],"source":["optimizer = tf.optimizers.Adam(learning_rate = learn_rate)"]},{"cell_type":"markdown","metadata":{"id":"ThsW01nSrgnY"},"source":["#### 1.7. Training and Testing:"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Wqu186uurgnY","colab":{"base_uri":"https://localhost:8080/","height":475},"executionInfo":{"status":"error","timestamp":1715866194797,"user_tz":-120,"elapsed":73304,"user":{"displayName":"Fabio M","userId":"09614366475601969276"}},"outputId":"dfb98854-cbe0-41ee-c127-3ce2ee956ea1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Step = 0   ,   Accuracy = 0.159 \n","\n","Step = 500   ,   Accuracy = 0.389 \n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-2ba7fca0ab33>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m                                \u001b[0;31m# Get a batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Testing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    870\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1501\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["@tf.function\n","def train_step(X, y, drop_probability):\n","    with tf.GradientTape() as tape:\n","        y_pred = model(X, drop_probability)\n","        loss = loss_fn(y, y_pred)\n","    gradients = tape.gradient(loss, [W1, W2, W3, W4, b1, b2, b3, b4])\n","    optimizer.apply_gradients(zip(gradients, [W1, W2, W3, W4, b1, b2, b3, b4]))\n","\n","# To replicate functionalities of tensorflow v1.* next_batch():\n","train_dataset = tf.data.Dataset.from_tensor_slices((mnist_train_images, mnist_train_labels))  # join together images and labels\n","train_dataset = train_dataset.repeat().batch(batch_size)                                      # yield batches that straddle epoch boundaries\n","# train_dataset = train_dataset.batch(batch_size).repeat()                                    # if clear epoch separation is needed\n","\n","# Training.\n","for i in range(n_epochs):\n","    batch_X, batch_y = next(iter(train_dataset))                                # Get a batch.\n","    train_step(batch_X, batch_y, drop_prob)\n","    # Testing.\n","    if i % 500 == 0:\n","        correct_predictions = tf.equal(tf.argmax(mnist_test_labels, axis=1), tf.argmax(model(mnist_test_images,0), axis=1))   # In argmax(), axis=1 means horizontal direction. No dropout for testing.\n","        accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))                                                   # Recast the Boolean as float32 first. Then calculate the mean.\n","        accuracy_value = accuracy.numpy()\n","        print(\"Step = {}   ,   Accuracy = {:5.3f}\".format(i, accuracy_value))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"provenance":[{"file_id":"1TBw917AgBwEHbJnbd0KiiOdZChcssDpE","timestamp":1715766968064}]}},"nbformat":4,"nbformat_minor":0}